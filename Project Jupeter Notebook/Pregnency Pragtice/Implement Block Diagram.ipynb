{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ee27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Pregnancy Risk.csv')\n",
    "\n",
    "df1 = df.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "col = ['Blood Group ( is Negative?)','Jaundice','Diabetes','Risk']\n",
    "for x in col:\n",
    "    df1[x] = encoder.fit_transform(df[x])\n",
    "    \n",
    "df2 = pd.get_dummies(df1,drop_first=True)\n",
    "\n",
    "X = df2.drop(['Risk','Height','Weight'],axis=1)\n",
    "y = df2.Risk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdaa9ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    614\n",
       "1    246\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25ee2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    247\n",
       "1    122\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff3c28d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8d2071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Accuracy:  1.0\n",
      "f1_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "\n",
      "Testing Data:\n",
      "Accuracy:  0.91\n",
      "f1_score:  0.91\n",
      "precision_score:  0.91\n",
      "recall_score:  0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rm_model = RandomForestClassifier()\n",
    "rm_model.fit(X_train,y_train)\n",
    "\n",
    "#train data\n",
    "y_pred = rm_model.predict(X_train)\n",
    "print('Training Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_train,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_train,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_train,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_train,y_pred, average='micro'),2))\n",
    "\n",
    "#test data\n",
    "y_pred = rm_model.predict(X_test)\n",
    "print('\\nTesting Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_test,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_test,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_test,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_test,y_pred, average='micro'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1d2824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Accuracy:  1.0\n",
      "f1_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "\n",
      "Testing Data:\n",
      "Accuracy:  0.86\n",
      "f1_score:  0.86\n",
      "precision_score:  0.86\n",
      "recall_score:  0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train,y_train)\n",
    "\n",
    "#train data\n",
    "y_pred = dt_model.predict(X_train)\n",
    "print('Training Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_train,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_train,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_train,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_train,y_pred, average='micro'),2))\n",
    "\n",
    "#test data\n",
    "y_pred = dt_model.predict(X_test)\n",
    "print('\\nTesting Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_test,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_test,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_test,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_test,y_pred, average='micro'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c51c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Accuracy:  0.71\n",
      "f1_score:  0.71\n",
      "precision_score:  0.71\n",
      "recall_score:  0.71\n",
      "\n",
      "Testing Data:\n",
      "Accuracy:  0.67\n",
      "f1_score:  0.67\n",
      "precision_score:  0.67\n",
      "recall_score:  0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "#train data\n",
    "y_pred = svm_model.predict(X_train)\n",
    "print('Training Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_train,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_train,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_train,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_train,y_pred, average='micro'),2))\n",
    "\n",
    "#test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('\\nTesting Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_test,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_test,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_test,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_test,y_pred, average='micro'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5febf6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Accuracy:  0.75\n",
      "f1_score:  0.75\n",
      "precision_score:  0.75\n",
      "recall_score:  0.75\n",
      "\n",
      "Testing Data:\n",
      "Accuracy:  0.71\n",
      "f1_score:  0.71\n",
      "precision_score:  0.71\n",
      "recall_score:  0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train,y_train)\n",
    "\n",
    "#train data\n",
    "y_pred = gnb_model.predict(X_train)\n",
    "print('Training Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_train,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_train,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_train,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_train,y_pred, average='micro'),2))\n",
    "\n",
    "#test data\n",
    "y_pred = gnb_model.predict(X_test)\n",
    "print('\\nTesting Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_test,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_test,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_test,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_test,y_pred, average='micro'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fde21ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Accuracy:  0.76\n",
      "f1_score:  0.76\n",
      "precision_score:  0.76\n",
      "recall_score:  0.76\n",
      "\n",
      "Testing Data:\n",
      "Accuracy:  0.72\n",
      "f1_score:  0.72\n",
      "precision_score:  0.72\n",
      "recall_score:  0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train,y_train)\n",
    "\n",
    "#train data\n",
    "y_pred = mnb_model.predict(X_train)\n",
    "print('Training Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_train,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_train,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_train,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_train,y_pred, average='micro'),2))\n",
    "\n",
    "#test data\n",
    "y_pred = mnb_model.predict(X_test)\n",
    "print('\\nTesting Data:')\n",
    "print('Accuracy: ', round(accuracy_score(y_test,y_pred),2))\n",
    "print('f1_score: ', round(f1_score(y_test,y_pred, average='micro'),2))\n",
    "print('precision_score: ', round(precision_score(y_test,y_pred, average='micro'),2))\n",
    "print('recall_score: ', round(recall_score(y_test,y_pred, average='micro'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1cbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c2aa8e9",
   "metadata": {},
   "source": [
    "# Other Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c5d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [RandomForestClassifier()]\n",
    "# names = ['RandomForest']\n",
    "# acc=0\n",
    "# prc=0\n",
    "# rec=0\n",
    "# def getScores(estimator, x, y):\n",
    "#     yPred = estimator.predict(x)\n",
    "#     return (accuracy_score(y, yPred), \n",
    "#             precision_score(y, yPred), \n",
    "#             recall_score(y, yPred))\n",
    "\n",
    "# def my_scorer(estimator, x, y):\n",
    "#     a, p, r = getScores(estimator, x, y)\n",
    "#     print ('Acc: ',a,'Pre: ', p,'Rec: ', r)\n",
    "#     return 0\n",
    "\n",
    "# for model, name in zip(models, names):\n",
    "#     print (name)\n",
    "#     cross_val_score(model, X, y,scoring=my_scorer, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5267815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(RandomForestClassifier(),X,y, cv=10, scoring=\"average_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93d701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
